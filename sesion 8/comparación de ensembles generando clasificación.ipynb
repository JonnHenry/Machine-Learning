{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este ejercicio es que el alumno utilice métodos ensemble y SVC para realizar clasificación en un dataset sintético. Además, el estudiante deberá encontrar los hyper-parámetros utilizando Grid y Randomized Search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecute y analice el siguiente código en términos de la estructura del dataset generado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons, make_classification\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrar_dataset(x, y):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12, 5))\n",
    "    \n",
    "    reduccion = TSNE(n_components=2, init='pca')\n",
    "    x_new = reduccion.fit_transform(x)\n",
    "    tmp_df = pd.DataFrame(np.column_stack([x_new, y]))\n",
    "    tmp_df.columns = [\"x1\", \"x2\", \"Y\"]\n",
    "    \n",
    "    sns.scatterplot(x=\"x1\", y=\"x2\", hue=\"Y\", data=tmp_df, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se generan el dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=18, n_redundant=1, n_classes=2, \n",
    "                           n_clusters_per_class=2, flip_y=0.05, random_state=1, class_sep=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mostrar_dataset(X[:1000], y[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.column_stack([X, y]))\n",
    "df.columns = [\"var_\"+str(i+1) for i in range(20)] + [\"clase\"]\n",
    "\n",
    "# genera la matriz de correlaciones entre atributos\n",
    "cor_mat= df[:].corr()\n",
    "mask = np.array(cor_mat)\n",
    "mask[np.tril_indices_from(mask)] = False\n",
    "fig=plt.gcf()\n",
    "fig.set_size_inches(30,12)\n",
    "sns.heatmap(data=cor_mat,mask=mask,square=True,annot=True,cbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_y = abs(cor_mat[\"clase\"])\n",
    "highest_corr = corr_y[corr_y > 0.3]\n",
    "highest_corr.sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En base a los resultados mostrados:\n",
    "\n",
    "- ¿Que características tiene el dataset generado?\n",
    "- ¿Que conjunto de variables podrían generar buenos resultados si son usadas para clasificación?\n",
    "- ¿Que variables proporcionan \"poca\" información para el problema?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecute el siguiente código donde se crean y prueban diferentes modelos de predicción. Para cada, seleccione manualmente valores para los hyper-parámetros y compare los resutlados de `accuracy` y `tiempo de entrenamiento`. \n",
    "\n",
    "Nota: No pase mucho tiempo tuneando manualmente los parámetros; el proceso de tuneado automático se realizará en el siguiente ejercicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se divide el dataset en datos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "Accuracy = 0.7700\n",
      "Tiempo de entrenamiento: 0.013 segundos\n"
     ]
    }
   ],
   "source": [
    "# Arbol de decisión\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# tiempo de entrenamiento\n",
    "start_time = time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Decision Tree\")\n",
    "print(\"Accuracy = {:.4f}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"Tiempo de entrenamiento: {:.3f} segundos\".format(training_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Accuracy = 0.8600\n",
      "Tiempo de entrenamiento: 0.293 segundos\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "start_time = time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Random Forest\")\n",
    "print(\"Accuracy = {:.4f}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"Tiempo de entrenamiento: {:.3f} segundos\".format(training_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost\n",
      "Accuracy = 0.7700\n",
      "Tiempo de entrenamiento: 0.158 segundos\n"
     ]
    }
   ],
   "source": [
    "# AdaBoost\n",
    "clf = AdaBoostClassifier(n_estimators=50)\n",
    "\n",
    "start_time = time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"AdaBoost\")\n",
    "print(\"Accuracy = {:.4f}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"Tiempo de entrenamiento: {:.3f} segundos\".format(training_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boost\n",
      "Accuracy = 0.8250\n",
      "Tiempo de entrenamiento: 0.448 segundos\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boost\n",
    "clf = GradientBoostingClassifier(n_estimators=100)\n",
    "\n",
    "start_time = time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Gradient Boost\")\n",
    "print(\"Accuracy = {:.4f}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"Tiempo de entrenamiento: {:.3f} segundos\".format(training_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost\n",
      "Accuracy = 0.8750\n",
      "Tiempo de entrenamiento: 0.295 segundos\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "xg_reg = xgb.XGBClassifier(learning_rate=0.5, max_depth=5, n_estimators=300)\n",
    "\n",
    "start_time = time.time()\n",
    "xg_reg.fit(X_train,y_train)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "y_pred = xg_reg.predict(X_test)\n",
    "print(\"XGBoost\")\n",
    "print(\"Accuracy = {:.4f}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"Tiempo de entrenamiento: {:.3f} segundos\".format(training_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC\n",
      "Accuracy = 0.8950\n",
      "Tiempo de entrenamiento: 0.030 segundos\n"
     ]
    }
   ],
   "source": [
    "# SVC\n",
    "clf = SVC(C=100, gamma=0.01)\n",
    "\n",
    "start_time = time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"SVC\")\n",
    "print(\"Accuracy = {:.4f}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"Tiempo de entrenamiento: {:.3f} segundos\".format(training_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modifique la función `make_classification` para que esta vez genere 30000 ejemplos y repetir el ejercicio 2.2 (puede usar los mismos hyper-parámetros que seleccionó inicialmente).\n",
    "\n",
    "¿Hubo variaciones en el accuracy y tiempo de ejecución? <br>\n",
    "¿De haber variaciones, por que?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vuelva a modificar la función `make_classification` para que genere 1000 ejemplos de entrenamiento. Encuentre los hyper-parámetros para los modelos antes utilizados mediante procesos de `GridSearchCV` o `RandomizedSearchCV`. La diferencia entre ambos métodos es que el primero hace una búsqueda exahustiva de los parámetros, mientras el segundo selecciona un número de configuraciones determinadas.\n",
    "\n",
    "Al final, genere un gráfico con los accuracies actualizados de los modelos. ¿Cambiaron los valores de los modelos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score :  0.8949999999999999\n",
      "Best Parameters :  {'C': 100.0, 'gamma': 0.01}\n",
      "Accuracy Score :  0.895\n"
     ]
    }
   ],
   "source": [
    "# Por ejemplo, el proceso para SVC es como sigue:\n",
    "\n",
    "clf_svc = SVC()\n",
    "\n",
    "parameters = {                       \n",
    "    \"C\": [1e2, 1e3, 1e4, 1e5, 1e6, 1e7],                                                      \n",
    "    \"gamma\": np.logspace(-2, 2, 5)                   \n",
    "}\n",
    "\n",
    "# clf_svc = RandomizedSearchCV(clf_svc, param_distributions=parameters, scoring=\"accuracy\", cv=5, n_jobs=-1, n_iter=15)\n",
    "clf_svc = GridSearchCV(clf_svc, param_grid=parameters, scoring=\"accuracy\", cv=5, n_jobs=-1)\n",
    "model_svc = clf_svc.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best score : \", model_svc.best_score_)\n",
    "print(\"Best Parameters : \", model_svc.best_params_)\n",
    "print(\"Accuracy Score : \", accuracy_score(model_svc.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realice un proceso parecido para el resto de modelos. \n",
    "\n",
    "Nota: si el número de combinaciones de hyper-parámetros es muy alta, se recomienda utilizar `RandomizedSearchCV`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use PCA para transformar el dataset a uno con menos dimensiones. Trace la curva de varianza explicada y entrene un modelo (escoja el que le parezca más adecuado) y calcule el `accuracy` obtenido. ¿Es buena idea para este problema utilizar PCA?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
