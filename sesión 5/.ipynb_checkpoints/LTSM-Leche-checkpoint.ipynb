{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este ejercicio es que el estudiante utilice Deep Neural Networks, específicamente la arquitectura LTSM para realizar forecast. Así mismo, el estudiante comenzará a analizar de forma objetiva series de tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1.1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecute y analice el siguiente código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5368a7a93079>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable_v2_behavior\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTES \n",
    "LAG = 60  # lagged values\n",
    "HIDDEN1 = 50  # Nro. neuronas de la primera capa\n",
    "HIDDEN2 = 50\n",
    "HIDDEN3 = 50\n",
    "HIDDEN4 = 50\n",
    "EPOCHS = 15  # número de epocas para entrenamiento. Si se demora mucho tiempo, baje el número de esta variable\n",
    "REDUCIR_DATASET = False  # si el dataset toma mucho tiempo en entrenarse, habilite esta variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"monthly-milk-production-pounds.csv\", index_col=0, parse_dates=[0])\n",
    "df.sort_values('MonthlyMilk')\n",
    "df['MonthlyMilk'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecutar esta línea de código, solo si su computador es de bajas prestaciones y el entrenamiento del modelo se demora demasiado cuando se usa todo el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para hacer el dataset más pequeño y no tarde tanto tiempo el entrenamiento\n",
    "if REDUCIR_DATASET:\n",
    "    df = df[df.index >= \"2010-01-01\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descripción gráfica del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 5))\n",
    "df.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descomponiendo la serie de tiempo en trend+seasonal+resid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este proceso se lo realiza en análisis de series de tiempo para entender si existen fenómenos como tendencias y efectos estacionales (tendencias que se repiten cada cierto tiempo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from matplotlib import pyplot\n",
    "result = seasonal_decompose(df, model='additive')\n",
    "\n",
    "fig, ax = plt.subplots(4, 1, figsize=(15, 10))\n",
    "\n",
    "result.observed.plot(ax=ax[0])\n",
    "ax[0].set_ylabel(\"Original\")\n",
    "\n",
    "result.seasonal.plot(ax=ax[1])\n",
    "ax[1].set_ylabel(\"Seasonal\")\n",
    "\n",
    "result.trend.plot(ax=ax[2])\n",
    "ax[2].set_ylabel(\"Trend\")\n",
    "\n",
    "result.resid.plot(ax=ax[3])\n",
    "ax[3].set_ylabel(\"Residuos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.autocorrelation_plot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En base a la información de la serie de tiempo, no existe un componente de tendencia claro: el componente de tendencia es altamente volátil. Además, no existe un componente estacional definido; este componente varía en una forma indeterminada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos para entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df[:'1974-12-31']\n",
    "test_data  = df['1974-12-31':]\n",
    "\n",
    "print('Número de observaciones: %d' % (len(df)))\n",
    "print('Dataset de entrenamiento:',train_data.shape)\n",
    "print('Dataset de prueba:', test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 5))\n",
    "train_data.plot(ax=ax)\n",
    "test_data.plot(ax=ax)\n",
    "plt.legend(['train', 'test']);\n",
    "plt.savefig('myfile.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En base a este gráfico:\n",
    "\n",
    "- Como podría comparar los valores de prueba y los de entrenamiento: tendencia, amplitud, etc\n",
    "- ¿Cree que es factible que un modelo pueda capturar las dinámicas intrínsecas de la serie de tiempo para predecir valores futuros acertadamente? ¿Por que?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizando y dividiendo los datos para entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# los datos son escalados en un rango de 0 y 1\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n",
    "test_data_scaled = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se actualiza el valor del dataframe con los valores normalizados\n",
    "df['MonthlyMilk'] = np.concatenate([train_data_scaled, test_data_scaled])[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window(ds, lags):\n",
    "    tmp_ind = ds.index.to_numpy()[lags:]\n",
    "    for i in range(lags):\n",
    "        tmp = ds.iloc[:, 0].shift(-(i+1))\n",
    "        ds = pd.concat([ds, tmp], axis=1)\n",
    "        \n",
    "    ds = ds.dropna()\n",
    "    ds.index = tmp_ind\n",
    "        \n",
    "    return ds\n",
    "\n",
    "ndf = window(df, LAG)\n",
    "train_data_scaled = ndf[:'1974-12-31'].to_numpy()\n",
    "test_data_scaled  = ndf['1974-12-31':].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Observaciones: %d' % (len(ndf)))\n",
    "print('Dataset de entrenamiento:',train_data_scaled.shape)\n",
    "print('Dataset de prueba:', test_data_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se asignan los datos para entrenamiento y prueba\n",
    "X_train, y_train = train_data_scaled[:, :-1], train_data_scaled[:, -1]\n",
    "X_test, y_test = test_data_scaled[:, :-1], test_data_scaled[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaping\n",
    "# 3D tensor with shape (batch_size, timesteps, input_dim).\n",
    "\n",
    "# Keras adminte datos de entrada del tipo (batch_size, timesteps, input_dim)\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creando y entrenando el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creando el modelo\n",
    "\n",
    "# initializing RNN\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# adding 1st LSTM layer and some dropout regularization\n",
    "model.add(tf.keras.layers.LSTM(units=HIDDEN1, input_shape=(X_train.shape[1], 1), return_sequences=True, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "# adding 2nd LSTM layer and some dropout regularization\n",
    "model.add(tf.keras.layers.LSTM(units=HIDDEN2, return_sequences=True))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "# adding 3rd LSTM layer and some dropout regularization\n",
    "model.add(tf.keras.layers.LSTM(units=HIDDEN3, return_sequences=True))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "# adding 4th LSTM layer and some dropout regularization\n",
    "model.add(tf.keras.layers.LSTM(units=HIDDEN4))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "# adding output layer\n",
    "model.add(tf.keras.layers.Dense(units=1))\n",
    "\n",
    "#compiling RNN\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "# model.compile(loss='mean_absolute_percentage_error', optimizer='adam')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=4)\n",
    "\n",
    "# fitting RNN on training set\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=EPOCHS,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.3,\n",
    "                    verbose=0,  # solo para efectos demostrativos\n",
    "                    #callbacks=[early_stopping],\n",
    "                    use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cambia la forma del vector de prueba para que sea aceptado por el modelo\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# predice con las matrices de entrenamiento y prueba\n",
    "trainPredict = model.predict(X_train)\n",
    "testPredict = model.predict(X_test)\n",
    "\n",
    "# invert predictions\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainY = scaler.inverse_transform([y_train])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testY = scaler.inverse_transform([y_test])\n",
    "\n",
    "# calcula root mean squared error\n",
    "#El Error cuadrado medio (MSE) o desviación cuadrada media (MSD) de un estimador mide el promedio de \n",
    "#cuadrados de error, es decir, la diferencia cuadrada media entre los valores estimados y el valor verdadero.\n",
    "#Error medio para el data set de entrenamiento\n",
    "\n",
    "trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Entrenamiento: %.2f RMSE' % (trainScore))\n",
    "\n",
    "#Error medio para el data set de prueba\n",
    "testScore = math.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Prueba: %.2f RMSE' % (testScore))\n",
    "\n",
    "\n",
    "#R-cuadrado es una medida estadística de lo cerca que están los datos de la línea de regresión ajustada. \n",
    "#También se conoce como el coeficiente de determinación, o el coeficiente de determinación múltiple para la regresión múltiple. \n",
    "\n",
    "# calcula el r2\n",
    "trainScore = r2_score(trainY[0], trainPredict[:,0])\n",
    "print('Entrenamiento: %.2f R2' % (trainScore))\n",
    "\n",
    "testScore = r2_score(testY[0], testPredict[:,0])\n",
    "print('Prueba: %.2f R2' % (testScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados de la predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.plot(testY[0], color = 'red', label =\"Actual Monthly Milk Production\")\n",
    "ax.plot(testPredict, color='blue', label = 'Predicted Monthly Milk Production')\n",
    "plt.title(\"Monthly Milk Production Prediction\")\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Natural gas price')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados del entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12, 5))\n",
    "ax.plot(history.history[\"loss\"], label=\"loss\")\n",
    "ax.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En base a los resultados de la predicción:\n",
    "\n",
    "- ¿Los resultados son lo suficientemente aceptables para aplicar este modelo en predicción? ¿Por que?\n",
    "- Durante el entrenamiento de la red, ¿Que realiza el `dropout`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Puede mejorar de alguna manera los resultados de este problema? \n",
    "\n",
    "Ayuda: puede modificar la arquitectura de la red (agregar/quitar capas), no usar todos los datos de entrenamiento, transformaciones de datos, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizar ahora SVR para el mismo problema. ¿Los resultados son mejores o peores?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparar los resultados anteriores con los resultados de un modelo persistente. Un modelo persistente en términos de forecast es un modelo que predice el valor futuro repitiendo lo que sucede actualmente; es decir, $F(x_{t+1})=x_t$. \n",
    "\n",
    "- Habiendo probado varios modelos, ¿Que modelo le parece mejor? ¿Por que?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
