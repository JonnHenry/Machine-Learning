{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este ejercicio es que el estudiante se familiarice con la funcionalidad de los auto-encoders. Los auto-encoders han ganado mucho espacio en la ciencia en los últimos años por sus capacidades para reducir dimensiones y también para eliminar ruido en los datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4.1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejecute y analice el siguiente código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input\n",
    "from keras.datasets import mnist\n",
    "from keras.regularizers import l1\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_autoencoder_outputs(autoencoder, n, dims):\n",
    "    \"\"\"Muestra imagenes originales en la primera fila, e imagenes codificadas en la segunda\n",
    "    \"\"\"\n",
    "    \n",
    "    # se decodifican imagenes de prueba\n",
    "    decoded_imgs = autoencoder.predict(x_test)\n",
    "\n",
    "    # number of example digits to show\n",
    "    n = 5\n",
    "    plt.figure(figsize=(10, 4.5))\n",
    "    for i in range(n):\n",
    "        # plot original image\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(x_test[i].reshape(*dims))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        if i == 2:\n",
    "            ax.set_title('Imagenes Originales')\n",
    "\n",
    "        # plot reconstruction \n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(decoded_imgs[i].reshape(*dims))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        if i == 2:\n",
    "            ax.set_title('Imagenes Reconstruidas')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se lee el dataset mnist con imagenes que contiene dígitos trazados a mano\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# se formatean los datos de prueba y entrenamiento\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arquitectura del encoder\n",
    "input_size = 784\n",
    "hidden_size = 128\n",
    "code_size = 32  # dimensionalidad final\n",
    "\n",
    "# se crea la estructura de encoder\n",
    "input_img = Input(shape=(input_size,))\n",
    "hidden_1 = Dense(hidden_size, activation='relu')(input_img)\n",
    "code = Dense(code_size, activation='relu')(hidden_1)\n",
    "hidden_2 = Dense(hidden_size, activation='relu')(code)\n",
    "output_img = Dense(input_size, activation='sigmoid')(hidden_2)\n",
    "\n",
    "# se instancia el encoder y se lo entrena con los datos de entrenamiento\n",
    "autoencoder = Model(input_img, output_img)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.fit(x_train, x_train, epochs=3)  # puede cambiar el valor de epochs para ver resultados distintos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_autoencoder_outputs(autoencoder, 5, (28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cree una arquitectura para el encoder-decoder más simple: El input size se mantiene, pero reduzca los valores de `hidden_size`y `code_size` hasta encontrar una combinación de valores mínimos de ambos valores que haga que las imagenes reconstruidas mantenga su calidad (la calidad implica que un humano pueda reconocer las imagenes reconstruidas) \n",
    "\n",
    "¿Que combinaciónd de parámetros: `hidden_size`y `code_size` logra minimizar la dimensionalidad de las imágenes y al mismo tiempo manteniendo un nivel aceptable de calidad de imagen? Muestre las imagenes resultantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente código modifica las imagenes de entrada para que tengan ruido. Ejecute y analice el código a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ahora se agrega ruido a las imagenes para probar la funcionalidad de denoising\n",
    "noise_factor = 0.4\n",
    "x_train_noisy = x_train + noise_factor * np.random.normal(size=x_train.shape) \n",
    "x_test_noisy = x_test + noise_factor * np.random.normal(size=x_test.shape)\n",
    "\n",
    "x_train_noisy = np.clip(x_train_noisy, 0.0, 1.0)\n",
    "x_test_noisy = np.clip(x_test_noisy, 0.0, 1.0)\n",
    "\n",
    "# se muestran las imágenes originales y con ruido\n",
    "n = 5\n",
    "plt.figure(figsize=(10, 4.5))\n",
    "for i in range(n):\n",
    "    # plot original image\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    if i == int(n/2):\n",
    "        ax.set_title('Imagenes Originales')\n",
    "\n",
    "    # plot noisy image \n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    if i == int(n/2):\n",
    "        ax.set_title('Imagenes con ruido')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrene un auto-encoder (puede ser el mismo que se usó en el ejercicio 4.1). Este auto-encoder se entrenará con las imagenes con ruido: `autoencoder.fit(x_train_noisy, x_train, epochs=10)`. Finalmente, muestre un plot de 3 filas donde se tengan las imagenes originales, las imagenes con ruido, y las imagenes generadas por el auto-encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4.5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cuál es el valor máximo del parámetro `noise_factor` que haga que todavía se encuentren resultados satisfactorios del auto-encoder entrenado en el ejercicio anterior?\n",
    "\n",
    "Muestre en una imagen los resultados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
